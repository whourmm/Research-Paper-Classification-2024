{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Don't need to run this command I've already done for you) Extracted Link From the Given Json\n",
    "This part is for extracting the specific link that contain \"scopus.com\" but exclude \"citedby\" \n",
    "\n",
    "Example Link with <a href=\"https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85170238281&origin=inward\">\"citedby\"</a> : <br>\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../image/with_citeby.png\" alt=\"image\" width=\"1000\" height=\"500\">\n",
    "</div>\n",
    "</br>\n",
    "Example Link without <a href=\"https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85050336797&origin=inward\">\"citedby\"</a> : <br>\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../image/without_citeby.png\" alt=\"image\" width=\"1000\" height=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scopus links have been saved in batches with a maximum of 200 links per file.\n"
     ]
    }
   ],
   "source": [
    "def extract_scopus_links(data, links=None):\n",
    "    \"\"\"\n",
    "    Recursively extract all Scopus links from a JSON object, excluding those with 'citedbyresults'.\n",
    "    \"\"\"\n",
    "    if links is None:\n",
    "        links = set()\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            extract_scopus_links(value, links)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            extract_scopus_links(item, links)\n",
    "    elif isinstance(data, str) and \"scopus.com\" in data and \"citedby\" not in data:\n",
    "        links.add(data)\n",
    "\n",
    "    return links\n",
    "\n",
    "def save_links_to_files(links, output_base, max_links_per_file):\n",
    "    \"\"\"\n",
    "    Save links to multiple files, each containing up to `max_links_per_file` links.\n",
    "    \"\"\"\n",
    "    links = list(links)\n",
    "    total_links = len(links)\n",
    "    num_files = (total_links // max_links_per_file) + (1 if total_links % max_links_per_file != 0 else 0)\n",
    "\n",
    "    for i in range(num_files):\n",
    "        start_idx = i * max_links_per_file\n",
    "        end_idx = start_idx + max_links_per_file\n",
    "        chunk_links = links[start_idx:end_idx]\n",
    "\n",
    "        output_file = f\"{output_base}_{i + 1}.txt\"\n",
    "        # Use utf-8 encoding when writing to the file\n",
    "        with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            outfile.write(\"\\n\".join(chunk_links))\n",
    "        print(f\"Saved {len(chunk_links)} links to {output_file}.\")\n",
    "\n",
    "def process_folders(base_folder, output_base, max_links_per_file=200):\n",
    "    \"\"\"\n",
    "    Process all files in subfolders, extracting Scopus links from files containing JSON content.\n",
    "    \"\"\"\n",
    "    collected_links = set()\n",
    "\n",
    "    # Walk through each folder and file\n",
    "    for root, dirs, files in os.walk(base_folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f\"Processing folder: {root} | File: {file}\")  # Print current folder and file being processed\n",
    "            try:\n",
    "                # Try to open and parse the file as JSON, even if it's not a .json file\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    try:\n",
    "                        # Try loading the content as JSON\n",
    "                        json_data = json.load(f)\n",
    "\n",
    "                        # Extract Scopus links\n",
    "                        links = extract_scopus_links(json_data)\n",
    "                        collected_links.update(links)\n",
    "                    except json.JSONDecodeError:\n",
    "                        # If the file content is not valid JSON, print a message\n",
    "                        print(f\"Skipping file (not valid JSON): {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    # Save collected links to multiple files\n",
    "    save_links_to_files(collected_links, output_base, max_links_per_file)\n",
    "\n",
    "# Step 1: Specify the folder where the extracted files are located\n",
    "base_folder = '../Project'  # Replace with the path to your extracted files\n",
    "\n",
    "# Step 2: Define the output base name for the link files\n",
    "output_base = 'scopus_links_2023'  # Base name for output files\n",
    "\n",
    "# Step 3: Process the folder and extract Scopus links, splitting into files with 200 links each\n",
    "process_folders(base_folder, output_base, max_links_per_file=200)\n",
    "\n",
    "# Step 4: Notify that the files are saved\n",
    "print(f\"Scopus links have been saved in batches with a maximum of 200 links per file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WebScrapping from the extracted link\n",
    "This part is for scraaping data including: \n",
    "- title\n",
    "- authors\n",
    "- article_info\n",
    "- abstract\n",
    "- categories/keyword\n",
    "- citation_info\n",
    "- document_info\n",
    "- author_tags\n",
    "- affiliations\n",
    "- funding\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../image/label_1.png\" alt=\"image\" width=\"1000\" height=\"500\">\n",
    "</div>\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../image/label_2.png\" alt=\"image\" width=\"1000\" height=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(url):\n",
    "    print(f\"Opening page: {url}\")  # Print progress as soon as the page starts loading\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration (useful for some environments)\n",
    "    webdriver_path = r\"C:\\users\\asus\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "# Create a Service object\n",
    "    service = Service(webdriver_path)\n",
    "\n",
    "# Optional: Add Chrome options if needed\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "# Initialize the WebDriver using the Service object\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "\n",
    "    try: \n",
    "\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "        data = {}\n",
    "\n",
    "        # Extraction logic (same as your provided code)\n",
    "        h2_elements = soup.select('h2')\n",
    "        for h2 in h2_elements:\n",
    "            inner_text = h2.get_text(strip=True)\n",
    "            data[\"title\"] = inner_text if inner_text else \"\"\n",
    "            # print(data)\n",
    "\n",
    "        author_section = soup.find('section', {'id': 'authorlist'})\n",
    "        if author_section:\n",
    "            author_tags = author_section.find_all('span', {'class': 'previewTxt'})\n",
    "            authors = [author_tag.get_text(strip=True) for author_tag in author_tags if author_tag.get_text(strip=True)]\n",
    "            data[\"authors\"] = authors if authors else []\n",
    "        else:\n",
    "            data[\"authors\"] = []\n",
    "\n",
    "        journal_info_span = soup.find('span', {'id': 'journalInfo'})\n",
    "        data[\"article_info\"] = journal_info_span.get_text(strip=True) if journal_info_span else \"\"\n",
    "\n",
    "        abstract_section = soup.find('section', {'id': 'abstractSection'})\n",
    "        if abstract_section:\n",
    "            p_tag = abstract_section.find('p')\n",
    "            data[\"abstract\"] = p_tag.get_text(strip=True) if p_tag else \"\"\n",
    "        else:\n",
    "            data[\"abstract\"] = \"\"\n",
    "\n",
    "        span_tag = soup.find('span', {'id': 'guestAccessSourceTitle'})\n",
    "        data[\"categories/keyword\"] = span_tag.get_text(strip=True) if span_tag else \"\"\n",
    "\n",
    "        citation_ul = soup.find('ul', {'id': 'citationInfo'})\n",
    "        citation_info = {}\n",
    "        citation_fields = [\"ISSN\", \"Source Type\", \"Original Language\"]\n",
    "        if citation_ul:\n",
    "            li_tags = citation_ul.find_all('li')\n",
    "            for i, li in enumerate(li_tags):\n",
    "                strong_tag = li.find('strong')\n",
    "                if strong_tag:\n",
    "                    strong_tag.extract()\n",
    "                clean_text = li.get_text(strip=True)\n",
    "                if i < len(citation_fields):\n",
    "                    citation_info[citation_fields[i]] = clean_text\n",
    "        data[\"citation_info\"] = citation_info\n",
    "\n",
    "        document_ul = soup.find('ul', {'id': 'documentInfo'})\n",
    "        document_info = {}\n",
    "        document_fields = [\"Document Type\", \"Publisher\"]\n",
    "        if document_ul:\n",
    "            li_tags = document_ul.find_all('li')\n",
    "            for i, li in enumerate(li_tags):\n",
    "                strong_tag = li.find('strong')\n",
    "                if strong_tag:\n",
    "                    strong_tag.extract()\n",
    "                clean_text = li.get_text(strip=True)\n",
    "                if i < len(document_fields):\n",
    "                    document_info[document_fields[i]] = clean_text\n",
    "        data[\"document_info\"] = document_info if document_info else {}\n",
    "\n",
    "        author_tags = soup.find_all('span', {'class': 'badges'})\n",
    "        authors = [author_tag.get_text(strip=True) for author_tag in author_tags if author_tag.get_text(strip=True)]\n",
    "        data[\"author_tags\"] = authors if authors else []\n",
    "\n",
    "        affiliation_section = soup.find('section', {'id': 'affiliationlist'})\n",
    "        if affiliation_section:\n",
    "            affiliation_tags = affiliation_section.find_all('li')\n",
    "            affiliations = [affiliation_tag.get_text(strip=True) for affiliation_tag in affiliation_tags if affiliation_tag.get_text(strip=True)]\n",
    "            data[\"affiliations\"] = affiliations if affiliations else []\n",
    "        else:\n",
    "            data[\"affiliations\"] = []\n",
    "\n",
    "        funding_rows = soup.find_all('tr', {'class': 'lightGreyBorderBottom'})\n",
    "        funding_data = []\n",
    "        for funding_row in funding_rows:\n",
    "            td_tags = funding_row.find_all('td')\n",
    "            funding_info = {\"Funding Sponsor\": \"\", \"Funding Number\": \"\", \"Acronym\": \"\"}\n",
    "            if len(td_tags) >= 3:\n",
    "                funding_info[\"Funding Sponsor\"] = td_tags[0].get_text(strip=True) if td_tags[0] else \"\"\n",
    "                funding_info[\"Funding Number\"] = td_tags[1].get_text(strip=True) if td_tags[1] else \"\"\n",
    "                funding_info[\"Acronym\"] = td_tags[2].get_text(strip=True) if td_tags[2] else \"\"\n",
    "            funding_data.append(funding_info)\n",
    "        data[\"funding\"] = funding_data if funding_data else []\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")  # Log errors during scraping\n",
    "        data = {}\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    print(f\"Finished scraping: {url}\")  # Notify when scraping for this URL is complete\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import required libraries\n",
    "# from kafka import KafkaProducer\n",
    "# import time\n",
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connect to kafka broker running in your local host (docker). Change this to your kafka broker if needed\n",
    "# kafka_broker = 'localhost:29092'\n",
    "# producer = KafkaProducer(\n",
    "#     bootstrap_servers=[kafka_broker],\n",
    "#     linger_ms=5000,  # Increased linger time\n",
    "#     max_block_ms=60000,  # Increase the max block time (default: 60000 ms = 1 minute)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data and send the data through Kafka Consumer\n",
    "1. Change ADD \"ADD PATH/TO/.TXT\" to the selected file path\n",
    "2. Change the output file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: scopus_links_2019.txt_1.txt with 200 URLs.\n",
      "\n",
      "Processing URL 1/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85046023620&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85046023620&origin=inward\n",
      "Completed URL 1/200.\n",
      "\n",
      "Processing URL 2/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85076265509&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85076265509&origin=inward\n",
      "Completed URL 2/200.\n",
      "\n",
      "Processing URL 3/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062640972&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062640972&origin=inward\n",
      "Completed URL 3/200.\n",
      "\n",
      "Processing URL 4/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85063279122&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85063279122&origin=inward\n",
      "Completed URL 4/200.\n",
      "\n",
      "Processing URL 5/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85069550026&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85069550026&origin=inward\n",
      "Completed URL 5/200.\n",
      "\n",
      "Processing URL 6/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85085863218&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85085863218&origin=inward\n",
      "Completed URL 6/200.\n",
      "\n",
      "Processing URL 7/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85061512111&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85061512111&origin=inward\n",
      "Completed URL 7/200.\n",
      "\n",
      "Processing URL 8/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85064326204&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85064326204&origin=inward\n",
      "Completed URL 8/200.\n",
      "\n",
      "Processing URL 9/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070777695&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070777695&origin=inward\n",
      "Completed URL 9/200.\n",
      "\n",
      "Processing URL 10/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065557033&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065557033&origin=inward\n",
      "Completed URL 10/200.\n",
      "\n",
      "Processing URL 11/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85076229169&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85076229169&origin=inward\n",
      "Completed URL 11/200.\n",
      "\n",
      "Processing URL 12/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85069928663&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85069928663&origin=inward\n",
      "Completed URL 12/200.\n",
      "\n",
      "Processing URL 13/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067179317&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067179317&origin=inward\n",
      "Completed URL 13/200.\n",
      "\n",
      "Processing URL 14/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85083001886&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85083001886&origin=inward\n",
      "Completed URL 14/200.\n",
      "\n",
      "Processing URL 15/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85056447778&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85056447778&origin=inward\n",
      "Completed URL 15/200.\n",
      "\n",
      "Processing URL 16/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85064633801&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85064633801&origin=inward\n",
      "Completed URL 16/200.\n",
      "\n",
      "Processing URL 17/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85071913626&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85071913626&origin=inward\n",
      "Completed URL 17/200.\n",
      "\n",
      "Processing URL 18/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082508161&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082508161&origin=inward\n",
      "Completed URL 18/200.\n",
      "\n",
      "Processing URL 19/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070786691&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070786691&origin=inward\n",
      "Completed URL 19/200.\n",
      "\n",
      "Processing URL 20/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070547689&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070547689&origin=inward\n",
      "Completed URL 20/200.\n",
      "\n",
      "Processing URL 21/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85074147634&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85074147634&origin=inward\n",
      "Completed URL 21/200.\n",
      "\n",
      "Processing URL 22/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85076212323&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85076212323&origin=inward\n",
      "Completed URL 22/200.\n",
      "\n",
      "Processing URL 23/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85073571196&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85073571196&origin=inward\n",
      "Completed URL 23/200.\n",
      "\n",
      "Processing URL 24/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85063267165&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85063267165&origin=inward\n",
      "Completed URL 24/200.\n",
      "\n",
      "Processing URL 25/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062321467&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062321467&origin=inward\n",
      "Completed URL 25/200.\n",
      "\n",
      "Processing URL 26/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85075350487&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85075350487&origin=inward\n",
      "Completed URL 26/200.\n",
      "\n",
      "Processing URL 27/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85063605347&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85063605347&origin=inward\n",
      "Completed URL 27/200.\n",
      "\n",
      "Processing URL 28/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85060377219&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85060377219&origin=inward\n",
      "Completed URL 28/200.\n",
      "\n",
      "Processing URL 29/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85057772904&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85057772904&origin=inward\n",
      "Completed URL 29/200.\n",
      "\n",
      "Processing URL 30/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85085520572&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85085520572&origin=inward\n",
      "Completed URL 30/200.\n",
      "\n",
      "Processing URL 31/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082515751&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082515751&origin=inward\n",
      "Completed URL 31/200.\n",
      "\n",
      "Processing URL 32/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85060328060&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85060328060&origin=inward\n",
      "Completed URL 32/200.\n",
      "\n",
      "Processing URL 33/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85061243135&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85061243135&origin=inward\n",
      "Completed URL 33/200.\n",
      "\n",
      "Processing URL 34/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070255341&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070255341&origin=inward\n",
      "Completed URL 34/200.\n",
      "\n",
      "Processing URL 35/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85079616477&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85079616477&origin=inward\n",
      "Completed URL 35/200.\n",
      "\n",
      "Processing URL 36/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067811443&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067811443&origin=inward\n",
      "Completed URL 36/200.\n",
      "\n",
      "Processing URL 37/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062186210&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062186210&origin=inward\n",
      "Completed URL 37/200.\n",
      "\n",
      "Processing URL 38/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85076179600&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85076179600&origin=inward\n",
      "Completed URL 38/200.\n",
      "\n",
      "Processing URL 39/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062521369&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062521369&origin=inward\n",
      "Completed URL 39/200.\n",
      "\n",
      "Processing URL 40/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85165214033&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85165214033&origin=inward\n",
      "Completed URL 40/200.\n",
      "\n",
      "Processing URL 41/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067076748&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067076748&origin=inward\n",
      "Completed URL 41/200.\n",
      "\n",
      "Processing URL 42/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070566526&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070566526&origin=inward\n",
      "Completed URL 42/200.\n",
      "\n",
      "Processing URL 43/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85073330994&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85073330994&origin=inward\n",
      "Completed URL 43/200.\n",
      "\n",
      "Processing URL 44/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065074990&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065074990&origin=inward\n",
      "Completed URL 44/200.\n",
      "\n",
      "Processing URL 45/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85051725467&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85051725467&origin=inward\n",
      "Completed URL 45/200.\n",
      "\n",
      "Processing URL 46/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85068990653&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85068990653&origin=inward\n",
      "Completed URL 46/200.\n",
      "\n",
      "Processing URL 47/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85066434744&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85066434744&origin=inward\n",
      "Completed URL 47/200.\n",
      "\n",
      "Processing URL 48/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065533444&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065533444&origin=inward\n",
      "Completed URL 48/200.\n",
      "\n",
      "Processing URL 49/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85064176690&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85064176690&origin=inward\n",
      "Completed URL 49/200.\n",
      "\n",
      "Processing URL 50/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85064055894&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85064055894&origin=inward\n",
      "Completed URL 50/200.\n",
      "\n",
      "Processing URL 51/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85074756059&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85074756059&origin=inward\n",
      "Completed URL 51/200.\n",
      "\n",
      "Processing URL 52/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070777727&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070777727&origin=inward\n",
      "Completed URL 52/200.\n",
      "\n",
      "Processing URL 53/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85069699539&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85069699539&origin=inward\n",
      "Completed URL 53/200.\n",
      "\n",
      "Processing URL 54/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082699817&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082699817&origin=inward\n",
      "Completed URL 54/200.\n",
      "\n",
      "Processing URL 55/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85073741734&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85073741734&origin=inward\n",
      "Completed URL 55/200.\n",
      "\n",
      "Processing URL 56/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85079452584&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85079452584&origin=inward\n",
      "Completed URL 56/200.\n",
      "\n",
      "Processing URL 57/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85072365396&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85072365396&origin=inward\n",
      "Completed URL 57/200.\n",
      "\n",
      "Processing URL 58/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85054041750&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85054041750&origin=inward\n",
      "Completed URL 58/200.\n",
      "\n",
      "Processing URL 59/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062102028&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062102028&origin=inward\n",
      "Completed URL 59/200.\n",
      "\n",
      "Processing URL 60/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85066828572&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85066828572&origin=inward\n",
      "Completed URL 60/200.\n",
      "\n",
      "Processing URL 61/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85056834636&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85056834636&origin=inward\n",
      "Completed URL 61/200.\n",
      "\n",
      "Processing URL 62/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85074733082&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85074733082&origin=inward\n",
      "Completed URL 62/200.\n",
      "\n",
      "Processing URL 63/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067939815&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067939815&origin=inward\n",
      "Completed URL 63/200.\n",
      "\n",
      "Processing URL 64/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85071767741&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85071767741&origin=inward\n",
      "Completed URL 64/200.\n",
      "\n",
      "Processing URL 65/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85078421248&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85078421248&origin=inward\n",
      "Completed URL 65/200.\n",
      "\n",
      "Processing URL 66/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062040129&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062040129&origin=inward\n",
      "Completed URL 66/200.\n",
      "\n",
      "Processing URL 67/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85075033033&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85075033033&origin=inward\n",
      "Completed URL 67/200.\n",
      "\n",
      "Processing URL 68/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065803082&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065803082&origin=inward\n",
      "Completed URL 68/200.\n",
      "\n",
      "Processing URL 69/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85073089044&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85073089044&origin=inward\n",
      "Completed URL 69/200.\n",
      "\n",
      "Processing URL 70/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85078111250&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85078111250&origin=inward\n",
      "Completed URL 70/200.\n",
      "\n",
      "Processing URL 71/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065494200&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065494200&origin=inward\n",
      "Completed URL 71/200.\n",
      "\n",
      "Processing URL 72/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062904772&origin=inward\n",
      "Finished scraping: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062904772&origin=inward\n",
      "Completed URL 72/200.\n",
      "\n",
      "Processing URL 73/200...\n",
      "Opening page: https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85072257805&origin=inward\n"
     ]
    }
   ],
   "source": [
    "# Folder containing the .txt files\n",
    "import os\n",
    "import pandas as pd\n",
    "folder_path = '../extracted_data/extracted_2019'  # Change to your folder path\n",
    "\n",
    "# List all .txt files in the folder\n",
    "txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "# Iterate through each .txt file\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    file_path = os.path.join(folder_path, txt_file)\n",
    "\n",
    "    # Open and read URLs from the current file\n",
    "    with open(file_path, 'r') as file:\n",
    "        urls = [line.strip() for line in file if line.strip()]\n",
    "        # print(urls)\n",
    "\n",
    "    total_urls = len(urls)\n",
    "    print(f\"Processing file: {txt_file} with {total_urls} URLs.\")\n",
    "\n",
    "    all_data = []  # Collect all data for this file\n",
    "\n",
    "    # Extract data from the URLs in the current file\n",
    "    for index, url in enumerate(urls, start=1):\n",
    "        print(f\"\\nProcessing URL {index}/{total_urls}...\")\n",
    "        # print(url)\n",
    "        try:\n",
    "            # Extract data for the current URL\n",
    "            extracted_data = extract_data(url)  # Calls the function that shows progress\n",
    "            all_data.append(extracted_data)\n",
    "            # print(all_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing URL {url}: {e}\")\n",
    "        print(f\"Completed URL {index}/{total_urls}.\")\n",
    "\n",
    "    # Convert extracted data into a pandas DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    # Define the output file name based on the .txt file\n",
    "    output_file = os.path.join(folder_path, f\"{os.path.splitext(txt_file)[0]}_output.csv\")\n",
    "    print(f\"Attempting to save to: {output_file}\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"File saved: {os.path.isfile(output_file)}\")\n",
    "\n",
    "    with open(output_file, 'r') as csvfile:\n",
    "        csv_content = csvfile.read()  # Read entire file content\n",
    "\n",
    "    # Send the entire CSV content to Kafka as a single message\n",
    "    print(f'Sending entire CSV content to Kafka: {csv_content[:100]}...')  # Display first 100 chars for logging\n",
    "    # producer.send('data_extracted', csv_content.encode('utf-8'))  # Send the CSV content\n",
    "    # time.sleep(2)\n",
    "\n",
    "    # # Ensure all messages are sent before exiting\n",
    "    # producer.flush()\n",
    "    # if(i ==0): break\n",
    "\n",
    "    \n",
    "    \n",
    "print(\"All files processed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsde-cedt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
