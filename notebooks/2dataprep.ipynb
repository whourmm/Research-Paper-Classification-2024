{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "import io\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_broker = 'localhost:29092'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (produce_messages):\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "Exception in thread Thread-5 (consume_messages):\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\threading.py\", line 982, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_2436\\2415202790.py\", line 2, in consume_messages\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_2436\\2415202790.py\", line 65, in produce_messages\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\kafka\\consumer\\group.py\", line 356, in __init__\n",
      "    self._client = KafkaClient(metrics=self._metrics, **self.config)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\kafka\\client_async.py\", line 244, in __init__\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\kafka\\producer\\kafka.py\", line 381, in __init__\n",
      "    self.config['api_version'] = self.check_version(timeout=check_timeout)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\kafka\\client_async.py\", line 927, in check_version\n",
      "    client = KafkaClient(metrics=self._metrics, metric_group_prefix='producer',\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\kafka\\client_async.py\", line 244, in __init__\n",
      "    raise Errors.NoBrokersAvailable()\n",
      "kafka.errors.NoBrokersAvailable: NoBrokersAvailable\n",
      "    self.config['api_version'] = self.check_version(timeout=check_timeout)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\envs\\dsde-cedt\\Lib\\site-packages\\kafka\\client_async.py\", line 927, in check_version\n",
      "    raise Errors.NoBrokersAvailable()\n",
      "kafka.errors.NoBrokersAvailable: NoBrokersAvailable\n"
     ]
    }
   ],
   "source": [
    "def consume_messages():\n",
    "    consumer = KafkaConsumer(\n",
    "        'data_extracted',\n",
    "        bootstrap_servers=[kafka_broker],\n",
    "        enable_auto_commit=True,\n",
    "        value_deserializer=lambda x: x.decode('utf-8')\n",
    "    )\n",
    "    response_consumer = KafkaConsumer(\n",
    "        'response_from_3',\n",
    "        bootstrap_servers=[kafka_broker],\n",
    "        enable_auto_commit=True,\n",
    "        value_deserializer=lambda x: x.decode('utf-8')\n",
    "    )\n",
    "    output_file_path = 'received_file.csv'\n",
    "    print('Running Consumer')\n",
    "\n",
    "    try:\n",
    "        for message in consumer:\n",
    "            print(f\"Received message: [{message.timestamp}:{message.offset}] {message.value}\")\n",
    "            \n",
    "            # Write the received message (CSV content) to a file\n",
    "            with open(output_file_path, 'w') as f:\n",
    "                f.write(message.value)  # Save the content to the file\n",
    "\n",
    "            print(f\"Message saved to {output_file_path}\")\n",
    "            \n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(output_file_path)\n",
    "            \n",
    "            # Data cleaning steps\n",
    "            df.drop(['authors', 'article_info', 'citation_info', 'document_info', 'affiliations', 'funding', 'abstract'], axis=1, inplace=True)\n",
    "            df.dropna()  # Drop rows with missing values\n",
    "            df.dropna(axis=1, inplace=True)  # Drop columns with missing values\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            \n",
    "            # Modify column names\n",
    "            df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "            \n",
    "            # Apply lowercase to all string values\n",
    "            df = df.apply(lambda col: col.str.lower() if col.dtype == \"object\" else col)\n",
    "            \n",
    "            # Save cleaned data to a new CSV\n",
    "            df.to_csv('cleaned_data.csv', index=False)\n",
    "            response_received = False\n",
    "            for resp_message in response_consumer:\n",
    "                print(f\"Received response: [{resp_message.timestamp}:{resp_message.offset}] {resp_message.value}\")\n",
    "                # You can implement custom logic to check for specific responses\n",
    "                if resp_message.value == 'success':  # Example of a simple response condition\n",
    "                    print(\"Response received. Proceeding with next message.\")\n",
    "                    response_received = True\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid response, waiting for valid acknowledgment...\")\n",
    "\n",
    "            if not response_received:\n",
    "                print(\"No valid response received. Retrying in a few seconds.\")\n",
    "                time.sleep(5)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while consuming: {e}\")\n",
    "\n",
    "def produce_messages():\n",
    "    csv_file_path = 'cleaned_data.csv'\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=[kafka_broker],\n",
    "        linger_ms=5000,\n",
    "        acks='all',\n",
    "        max_block_ms=60000\n",
    "    )\n",
    "\n",
    "    while not os.path.exists(csv_file_path):\n",
    "        print(f\"Waiting for {csv_file_path} to appear...\")\n",
    "        time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "\n",
    "    print(f\"{csv_file_path} found! Proceeding to send data...\")\n",
    "    with open(csv_file_path, 'r') as csvfile:\n",
    "        csv_content = csvfile.read()  # Read entire file content\n",
    "    csv_file_path = 'cleaned_data.csv'\n",
    "    # Send the entire CSV content to Kafka as a single message\n",
    "    print(f'Sending entire CSV content to Kafka: {csv_content[:100]}...')  # Display first 100 chars for logging\n",
    "    producer.send('processed_data', csv_content.encode('utf-8'))  # Send the CSV content\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Ensure all messages are sent before exiting\n",
    "    producer.flush()\n",
    "\n",
    "\n",
    "# Running producer and consumer in separate threads\n",
    "consumer_thread = threading.Thread(target=consume_messages)\n",
    "producer_thread = threading.Thread(target=produce_messages)\n",
    "\n",
    "consumer_thread.start()\n",
    "producer_thread.start()\n",
    "\n",
    "consumer_thread.join()\n",
    "producer_thread.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsde-cedt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc7b3cfd4489cced733c03bf4c83ac3dc97f9af36e7be94b3e061184a3cfec20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
